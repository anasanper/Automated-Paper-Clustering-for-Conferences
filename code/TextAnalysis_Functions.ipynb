{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aeaefab",
   "metadata": {},
   "source": [
    "# Functions for GitHub Repository: Automated-Paper-Clustering-for-Conference\n",
    "\n",
    "This notebook contains functions for generating word clouds, loading tracks, generating combinations of papers from the same and different tracks, calculating similarity scores, and tuning hyperparameters.\n",
    "\n",
    "In the context of this notebook, a \"track\" refers to a predefined grouping or category of papers. These tracks are often organized based on common themes, topics, or conference sessions. The functions provided here are designed to analyze and compare papers within these tracks, as well as across different tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbe6ce",
   "metadata": {},
   "source": [
    "<pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd670b",
   "metadata": {},
   "source": [
    "## Function to Generate Word Cloud\n",
    "\n",
    "This function generates a word cloud for the text of a specified paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def word_cloud(folder_texts, i)\n",
    "\n",
    "    # Change to the directory where text files are stored\n",
    "    os.chdir(folder_texts)\n",
    "\n",
    "    # List all files in the text files directory\n",
    "    files = os.listdir(folder_texts)\n",
    "\n",
    "    # Select the i-th file from the list\n",
    "    file_name = files[i]\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        # Read the content of the file and store it in the 'text' variable\n",
    "        text = file.read()\n",
    "\n",
    "    # Create a WordCloud based on the processed text\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "\n",
    "    # Display the WordCloud in a graphical representation\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")  # Turn off the axes for a cleaner presentation\n",
    "    plt.show()  # Show the graphical representation of the WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0f0f4",
   "metadata": {},
   "source": [
    "### Track Analysis Functions\n",
    "\n",
    "These functions are designed to analyze tracks of papers.\n",
    "\n",
    "These functions perform various operations such as loading tracks from files, generating combinations of papers within the same track, generating combinations of papers from different tracks, calculating similarity scores between papers within and across tracks, and computing metrics based on these similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track(folder_tracks, i, name):\n",
    "    \"\"\"\n",
    "    Load a track from a file.\n",
    "\n",
    "    Args:\n",
    "    - folder_tracks (str): Path to the folder containing track files.\n",
    "    - i (int): Index of the track.\n",
    "    - name (str): Name of the track file.\n",
    "\n",
    "    Returns:\n",
    "    - Loaded track.\n",
    "    \"\"\"\n",
    "    os.chdir(folder_tracks)\n",
    "    with open(name, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def combinations_same(folder_tracks):\n",
    "    \"\"\"\n",
    "    Generate all combinations of pairs of papers within the same track.\n",
    "\n",
    "    Args:\n",
    "    - folder_tracks (str): Path to the folder containing track files.\n",
    "\n",
    "    Returns:\n",
    "    - List of all combinations of pairs of papers within the same track.\n",
    "    \"\"\"\n",
    "    comb_total = []\n",
    "    os.chdir(folder_tracks) \n",
    "    names_tracks = os.listdir(folder_tracks)\n",
    "    for i, name in enumerate(names_tracks):\n",
    "        track = load_track(folder_tracks, i, name)\n",
    "        comb = list(itertools.combinations(track, 2))\n",
    "        comb_total.extend(comb)\n",
    "    return comb_total\n",
    "\n",
    "pairs_tracks = combinations_same(r'C:\\Users\\ana_s\\OneDrive\\Escritorio\\tfg\\archivos\\tracks')\n",
    "\n",
    "def combinations_diff(folder_tracks, papers):\n",
    "    \"\"\"\n",
    "    Generate all combinations of pairs of papers from different tracks.\n",
    "\n",
    "    Args:\n",
    "    - folder_tracks (str): Path to the folder containing track files.\n",
    "    - papers (list): List of all paper names in the corpus.\n",
    "\n",
    "    Returns:\n",
    "    - List of all combinations of pairs of papers from different tracks.\n",
    "    \"\"\"\n",
    "    comb_total = []\n",
    "    os.chdir(folder_tracks) \n",
    "    names_tracks = os.listdir(folder_tracks)\n",
    "    for i, name in enumerate(names_tracks):\n",
    "        track = load_track(folder_tracks, i, name)\n",
    "        for j in track:\n",
    "            for paper in papers:\n",
    "                k = papers.index(paper)\n",
    "                if k not in track:\n",
    "                    comb_total.append((j, k))\n",
    "    return comb_total\n",
    "\n",
    "# Assuming 'papers' is defined somewhere before calling combinations_diff\n",
    "papers = [...]  # List of all paper names in the corpus\n",
    "pairs_diff_track = combinations_diff(r'C:\\Users\\ana_s\\OneDrive\\Escritorio\\tfg\\archivos\\tracks', papers)\n",
    "\n",
    "def same_track(matrix_sim):\n",
    "    \"\"\"\n",
    "    Calculate similarity between papers from the same track.\n",
    "\n",
    "    Args:\n",
    "    - matrix_sim: Similarity matrix.\n",
    "\n",
    "    Returns:\n",
    "    - List of similarities between papers from the same track.\n",
    "    \"\"\"\n",
    "    sim_track = []\n",
    "    for pair in pairs_tracks:\n",
    "        i, j = pair\n",
    "        sim_track.append(matrix_sim[i][j])\n",
    "    return sim_track\n",
    "\n",
    "def diff_track(matrix_sim):\n",
    "    \"\"\"\n",
    "    Calculate similarity between papers from different tracks.\n",
    "\n",
    "    Args:\n",
    "    - matrix_sim: Similarity matrix.\n",
    "\n",
    "    Returns:\n",
    "    - List of similarities between papers from different tracks.\n",
    "    \"\"\"\n",
    "    sim_no_track = []\n",
    "    for pair in pairs_diff_track:\n",
    "        i, j = pair\n",
    "        sim_no_track.append(matrix_sim[i][j])\n",
    "    return sim_no_track\n",
    "\n",
    "def metric(matrix_sim):\n",
    "    \"\"\"\n",
    "    Calculate the metric based on similarity between papers\n",
    "    from the same and different tracks.\n",
    "\n",
    "    Args:\n",
    "    - matrix_sim: Similarity matrix.\n",
    "\n",
    "    Returns:\n",
    "    - Metric score.\n",
    "    \"\"\"\n",
    "    # Same track\n",
    "    sim_track = same_track(matrix_sim)\n",
    "    median_max = statistics.median(sim_track)\n",
    "\n",
    "    # Different track\n",
    "    sim_no_track = diff_track(matrix_sim)\n",
    "    median_min = statistics.median(sim_no_track)\n",
    "\n",
    "    score = median_max - median_min\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84faf26",
   "metadata": {},
   "source": [
    "### Function for Hyperparameter Tuning\n",
    "\n",
    "This function performs hyperparameter tuning by iterating through all parameter combinations and calculating their scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c85465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Preprocessing parameters\n",
    "root_functions = [stem, lemmatize]\n",
    "\n",
    "# TfidfVectorizer parameters\n",
    "max_df_values = np.arange(0.7, 1.01, 0.1)  # Ignore terms that appear in more than 'max_df' documents: [0.8:1] (80%)\n",
    "min_df_values = np.arange(0.0, 0.4, 0.1)  # Ignore terms that appear in less than 'min_df' documents: [0:0.2] (20%)\n",
    "ngram_ranges = [(1, 1), (1, 2)]  # Token: word / word and bi-gram (consecutive word pairs)\n",
    "max_features_values = [20, 50, 200, 500]  # Take the top 'max_features' terms that are most frequent in the corpus\n",
    "sublinear_tf_values = [True, False]  # Apply logarithm to the frequency of each token in the corpus\n",
    "\n",
    "# Hyperparameter combinations\n",
    "combinations = list(product(root_functions, max_df_values, min_df_values, max_features_values, ngram_ranges, \n",
    "                            sublinear_tf_values))\n",
    "\n",
    "# Calculate the score for each combination of parameters\n",
    "# Input: Parameter combination\n",
    "# Output: Score, hyperparameters, vector with similarities between papers of the same track,\n",
    "#and vector with similarities between papers of different tracks\n",
    "def tuning(combination, folder_texts):\n",
    "    # Preprocessing\n",
    "    parameters = {'root_function': combination[0]}\n",
    "    corpus = txt_corpus(folder_texts, combination[0])\n",
    "\n",
    "    # Tfidf\n",
    "    parameters_tfidf = {'max_df': combination[1],\n",
    "                        'min_df': combination[2],\n",
    "                        'stop_words': 'english',\n",
    "                        'max_features': combination[3],\n",
    "                        'sublinear_tf': combination[5],\n",
    "                        'ngram_range': combination[4]}\n",
    "    matrix_tfidf = tfidf(corpus, parameters_tfidf)\n",
    "    parameters.update(parameters_tfidf)\n",
    "\n",
    "    # Cosine similarity\n",
    "    matrix_sim = cosine_similarity(matrix_tfidf)\n",
    "    score = metric(matrix_sim)\n",
    "\n",
    "    return score, parameters\n",
    "\n",
    "# Iterate through all parameter combinations and calculate their score\n",
    "start_time = time.time()\n",
    "i = 0\n",
    "scores = []\n",
    "hyperparameters = []\n",
    "\n",
    "while True:\n",
    "    combination = combinations[i]\n",
    "    score, parameters = tuning(combination, r'C:\\Users\\ana_s\\OneDrive\\Escritorio\\tfg\\archivos\\texts_extract')\n",
    "    hyperparameters.append(parameters)  # List with parameters for each iteration\n",
    "    scores.append(score)  # List with the score for each iteration\n",
    "\n",
    "    i += 1\n",
    "    if i == len(combinations):\n",
    "        break\n",
    "elapsed_time = time.time() - start_time\n",
    "max_score = max(scores)  # Choose the maximum score\n",
    "hyperparameters_max = hyperparameters[scores.index(max_score)]  # Choose the parameters that achieve the maximum score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b191255",
   "metadata": {},
   "source": [
    "### Function to Plot Scores\n",
    "\n",
    "This function plots the scores corresponding to each hyperparameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_plot(scores, combinations):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Create a dictionary to store scores corresponding to each hyperparameter value\n",
    "    scores_dict = {}\n",
    "\n",
    "    # List to store combination information corresponding to each score\n",
    "    combination_info = []\n",
    "\n",
    "    # Fill the dictionary and combination information\n",
    "    for combination, score in zip(combinations, scores):\n",
    "        combination_info.append((combination, score))\n",
    "        for hyperparam_value in combination:\n",
    "            # Convert to a string if it is a boolean\n",
    "            if isinstance(hyperparam_value, bool):\n",
    "                hyperparam_value = str(hyperparam_value)\n",
    "            if hyperparam_value not in scores_dict:\n",
    "                scores_dict[hyperparam_value] = [score]\n",
    "            else:\n",
    "                scores_dict[hyperparam_value].append(score)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(nrows=len(scores_dict), figsize=(5, 4 * len(scores_dict)))\n",
    "\n",
    "    # Iterate over the dictionary and plot on different subplots\n",
    "    for i, (hyperparam_value, hyperparam_scores) in enumerate(scores_dict.items()):\n",
    "        axs[i].plot(hyperparam_scores, label=f'{hyperparam_value}')\n",
    "        axs[i].legend()\n",
    "\n",
    "        # Find the top 5 values\n",
    "        max_indices = sorted(range(len(hyperparam_scores)), key=lambda j: hyperparam_scores[j], reverse=True)[:5]\n",
    "\n",
    "        # Highlight the top 5 values with a marker or label\n",
    "        axs[i].scatter(max_indices, [hyperparam_scores[idx] for idx in max_indices], color='red', marker='o', label='Maximums')\n",
    "\n",
    "        # Draw a horizontal line at the mean\n",
    "        mean_score = sum(hyperparam_scores) / len(hyperparam_scores)\n",
    "        axs[i].axhline(y=mean_score, color='green', linestyle='--', label='Mean')\n",
    "        axs[i].legend()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Set manual limits to ensure consistency in x and y axes\n",
    "    for ax in axs:\n",
    "        ax.set_ylim(-0.051, 0.02)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return scores_dict, combination_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643cbad",
   "metadata": {},
   "source": [
    "## Function to Calculate Similarity Scores\n",
    "This function calculates similarity scores between predicted groups and true groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b33ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_scores(predicted_groups, true_groups):\n",
    "    # List to store final similarity scores.\n",
    "    final_scores = []\n",
    "\n",
    "    # Iterate through each predicted group.\n",
    "    for predicted_group in predicted_groups:\n",
    "        total_score = 0  # Initialize total score for the predicted group.\n",
    "\n",
    "        # Iterate through each element in the predicted group.\n",
    "        for predicted_element in predicted_group:\n",
    "            matches = 0  # Initialize count of matching elements.\n",
    "            len_predicted = len(predicted_group)  # Length of predicted group.\n",
    "\n",
    "            # Iterate through each true group.\n",
    "            for true_group in true_groups:\n",
    "                if predicted_element in true_group:\n",
    "                    len_true = len(true_group)  # Length of true group.\n",
    "\n",
    "                    # Iterate through each element in the true group.\n",
    "                    for true_element in true_group:\n",
    "                        if true_element in predicted_group and true_element != predicted_element:\n",
    "                            matches += 1  # Increment matches count.\n",
    "\n",
    "            # Calculate similarity score for the current predicted element.\n",
    "            element_score = matches / (len_true - 1) if len_true > 1 else 0\n",
    "            total_score += element_score  # Add element score to total score.\n",
    "\n",
    "        # Calculate final similarity score for the predicted group.\n",
    "        final_score = total_score / len_predicted if len_predicted > 0 else 0\n",
    "        final_scores.append(final_score)  # Add final score to the list.\n",
    "\n",
    "    # Print final scores and average score.\n",
    "    print('Final Scores:', final_scores)\n",
    "    print('Average Score:', statistics.mean(final_scores))\n",
    "    \n",
    "calculate_similarity_scores(kmeans.labels_, tracks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
